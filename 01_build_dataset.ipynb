{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01_build_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapaloCat/Traffic-Sign-Detection-System/blob/master/01_build_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "718GBnHeSBsx"
      },
      "source": [
        "## The German Traffic Sign Benchmark - Data Preparation\n",
        "\n",
        "Collaborator 1: Panagiotis Michalopoulos\n",
        "\n",
        "Collaborator 2: Filip Finfando"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yXMJLE-tSBsy"
      },
      "source": [
        "Download full data set from http://benchmark.ini.rub.de/?section=gtsdb&subsection=dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGXxyt2Aw239",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v4Rb63upTtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -c https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
        "!unzip FullIJCNN2013.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRrPdDbM5XRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo pip install keras==2.1.6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKJgrFLA5cLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AjVJoOb8SBtB",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "IMG_HEIGHT = 600\n",
        "SIGN_SIZE = (96, 96)\n",
        "\n",
        "# Function for reading the images\n",
        "def readImages(rootpath, images_range, signs_range):\n",
        "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
        "    Arguments: path to the traffic sign data, for example 'FullIJCNN2013'\n",
        "    Returns:   list of images, list of corresponding labels'''\n",
        "    images = {} # original image\n",
        "    scales = {} # original scale\n",
        "    for num in images_range:\n",
        "        filename = rootpath + '/' + \"{:05d}\".format(num) + '.ppm'\n",
        "        img = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
        "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        scale = IMG_HEIGHT / float(img.shape[0])\n",
        "        img_resized = cv2.resize(img, (int(img.shape[1]*scale),int(img.shape[0]*scale)))\n",
        "        images.setdefault(filename,[]).append(img_resized)\n",
        "        scales.setdefault(filename,[]).append(scale)\n",
        "\n",
        "    files = [] # filenames\n",
        "    signs = [] # traffic sign image\n",
        "    bboxes = [] # corresponding box detection\n",
        "    labels = [] # traffic sign type\n",
        "    data = np.genfromtxt(rootpath + '/' + 'gt.txt', delimiter=';', dtype=str, usecols=range(0, 6))\n",
        "    for elem in signs_range:\n",
        "        filename = rootpath + '/' + data[elem][0]\n",
        "        img = images.get(filename)[0]\n",
        "        scale = scales.get(filename)[0]\n",
        "        bbox = np.array([int(data[elem][1]), int(data[elem][2]), int(data[elem][3]), int(data[elem][4])]) * scale\n",
        "        sign = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "        sign_resized = cv2.resize(sign, SIGN_SIZE)\n",
        "        files.append(filename)\n",
        "        signs.append(sign_resized)\n",
        "        bboxes.append(bbox)\n",
        "        labels.append(data[elem][5])\n",
        "    return images, files, signs, bboxes, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NWA9VZTuSBtE",
        "colab": {}
      },
      "source": [
        "# The German Traffic Sign Recognition Benchmark\n",
        "train_images, train_files, train_signs, train_bboxes, train_labels = readImages('FullIJCNN2013', range(0,600), range(0,852))\n",
        "test_images, test_files, test_signs, test_bboxes, test_labels = readImages('FullIJCNN2013', range(600,900), range(852,1213))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZhX1ebSxSBtH",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "# Show examples from each class\n",
        "class_names = np.unique(train_labels)\n",
        "num_classes = len(class_names)\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(6, 9, 1 + i, xticks=[], yticks=[])\n",
        "    ax.set_title(class_names[i])\n",
        "    indices = np.where(np.isin(train_labels, class_names[i]))[0]\n",
        "    plt.imshow(cv2.cvtColor(train_signs[int(np.random.choice(indices, 1))], cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QIcE16qnSBtL",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "train_files, train_signs, train_bboxes, train_labels = shuffle(train_files, train_signs, train_bboxes, train_labels)\n",
        "# plt.imshow(cv2.cvtColor(train_images.get(train_files[0])[0], cv2.COLOR_BGR2RGB))\n",
        "# plt.show()\n",
        "# plt.imshow(cv2.cvtColor(train_signs[0], cv2.COLOR_BGR2RGB))\n",
        "# plt.show()\n",
        "# print(train_bboxes[0])\n",
        "# print(train_labels[0])\n",
        "\n",
        "# Data pre-processing\n",
        "tr_signs = np.array(train_signs)[0:600]\n",
        "tr_labels = np.array(train_labels)[0:600]\n",
        "va_signs = np.array(train_signs)[600:852]\n",
        "va_labels = np.array(train_labels)[600:852]\n",
        "te_signs = np.array(test_signs)\n",
        "te_labels = np.array(test_labels)\n",
        "\n",
        "tr_signs = tr_signs.astype('float32')\n",
        "va_signs = va_signs.astype('float32')\n",
        "te_signs = te_signs.astype('float32')\n",
        "tr_signs /= 255.0\n",
        "va_signs /= 255.0\n",
        "te_signs /= 255.0\n",
        "\n",
        "from keras.utils import np_utils\n",
        "tr_labels = np_utils.to_categorical(tr_labels, num_classes)\n",
        "va_labels = np_utils.to_categorical(va_labels, num_classes)\n",
        "te_labels = np_utils.to_categorical(te_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "unwgrhVSSBtP",
        "colab": {}
      },
      "source": [
        "# Tensorboard\n",
        "from time import time\n",
        "from keras.callbacks import TensorBoard\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j0eVsxuvSBtS"
      },
      "source": [
        "## Region Proposal Network (RPN)\n",
        "\n",
        "Keras 2.1.6 is required for the RPN to work. Install by executing: sudo pip install Keras==2.1.6 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B78KOl60SBtT",
        "colab": {}
      },
      "source": [
        "ANCHOR_RATIOS = (0.5, 1.0, 2.0)\n",
        "ANCHOR_STRIDE = 16\n",
        "ANCHOR_SIZES = (32, 64, 128, 256, 512)\n",
        "MAX_SIZE = 1344\n",
        "MIN_SIZE = 0\n",
        "\n",
        "# Parameters to play with to modify the number of proposal in each image\n",
        "TEST_PRE_NMS_TOPK = 100000 # The maximum number of positive samples taken during proposal generation, pre NMS\n",
        "TEST_POST_NMS_TOPK = 500 # The maximum number of positive samples taken during proposal generation, post NMS\n",
        "PROPOSAL_NMS_THRESH = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nfF1WOotSBtV",
        "colab": {}
      },
      "source": [
        "\"\"\"Operations for [N, 4] numpy arrays representing bounding boxes.\n",
        "Example box operations that are supported:\n",
        "  * Areas: compute bounding box areas\n",
        "  * IOU: pairwise intersection-over-union scores\n",
        "\"\"\"\n",
        "def area(boxes):\n",
        "    \"\"\"Computes area of boxes.\n",
        "    Args:\n",
        "    boxes: Numpy array with shape [N, 4] holding N boxes\n",
        "    Returns:\n",
        "    a numpy array with shape [N*1] representing box areas\n",
        "    \"\"\"\n",
        "    return (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
        "\n",
        "def intersection(boxes1, boxes2):\n",
        "    \"\"\"Compute pairwise intersection areas between boxes.\n",
        "    Args:\n",
        "    boxes1: a numpy array with shape [N, 4] holding N boxes\n",
        "    boxes2: a numpy array with shape [M, 4] holding M boxes\n",
        "    Returns:\n",
        "    a numpy array with shape [N*M] representing pairwise intersection area\n",
        "    \"\"\"\n",
        "    [x_min1, y_min1, x_max1, y_max1] = np.split(boxes1, 4, axis=1)\n",
        "    [x_min2, y_min2, x_max2, y_max2] = np.split(boxes2, 4, axis=1)\n",
        "    all_pairs_min_ymax = np.minimum(y_max1, np.transpose(y_max2))\n",
        "    all_pairs_max_ymin = np.maximum(y_min1, np.transpose(y_min2))\n",
        "    intersect_heights = np.maximum(np.zeros(all_pairs_max_ymin.shape, dtype='f4'),all_pairs_min_ymax - all_pairs_max_ymin)\n",
        "    all_pairs_min_xmax = np.minimum(x_max1, np.transpose(x_max2))\n",
        "    all_pairs_max_xmin = np.maximum(x_min1, np.transpose(x_min2))\n",
        "    intersect_widths = np.maximum(np.zeros(all_pairs_max_xmin.shape, dtype='f4'),all_pairs_min_xmax - all_pairs_max_xmin)\n",
        "    return intersect_heights * intersect_widths\n",
        "\n",
        "def iou(boxes1, boxes2):\n",
        "    \"\"\"Computes pairwise intersection-over-union between box collections.\n",
        "    Args:\n",
        "    boxes1: a numpy array with shape [N, 4] holding N boxes.\n",
        "    boxes2: a numpy array with shape [M, 4] holding M boxes.\n",
        "    Returns:\n",
        "    a numpy array with shape [N, M] representing pairwise iou scores.\n",
        "    \"\"\"\n",
        "    intersect = intersection(boxes1, boxes2)\n",
        "    area1 = area(boxes1)\n",
        "    area2 = area(boxes2)\n",
        "    union = np.expand_dims(area1, axis=1) + np.expand_dims(area2, axis=0) - intersect\n",
        "    return intersect / union\n",
        "\n",
        "def ioa(boxes1, boxes2):\n",
        "    \"\"\"Computes pairwise intersection-over-area between box collections.\n",
        "    Intersection-over-area (ioa) between two boxes box1 and box2 is defined as\n",
        "    their intersection area over box2's area. Note that ioa is not symmetric,\n",
        "    that is, IOA(box1, box2) != IOA(box2, box1).\n",
        "    Args:\n",
        "    boxes1: a numpy array with shape [N, 4] holding N boxes.\n",
        "    boxes2: a numpy array with shape [M, 4] holding N boxes.\n",
        "    Returns:\n",
        "    a numpy array with shape [N, M] representing pairwise ioa scores.\n",
        "    \"\"\"\n",
        "    intersect = intersection(boxes1, boxes2)\n",
        "    inv_areas = np.expand_dims(1.0 / area(boxes2), axis=0)\n",
        "    return intersect * inv_areas\n",
        "\n",
        "def clip_boxes(bboxes, clip_box, alpha):\n",
        "    \"\"\"\n",
        "    This function clip the bboxes to the border of the image\n",
        "\n",
        "    :param bboxes: array of shape (Nx4) containing the coordinates of the bboxes\n",
        "                in the format: xmin, ymin, xmax, ymax.\n",
        "    :param clip_box: array of shape (4,) containing the coordinates of the image\n",
        "                in the format: xmin, ymin, xmax ymax.\n",
        "    :param alpha:float, minimum threshold of area acepted. If a clipped bbpx\n",
        "                    have an relative area (wrt their original area) less than\n",
        "                    alpha, it is discarded.\n",
        "    :return: numpy array Nx4 of the clipped bboxes with their new coordinates\n",
        "            in the format xmin, ymin, xmax, ymax.\n",
        "    \"\"\"\n",
        "    areas = area(bboxes)\n",
        "    bboxes[:, 0] = np.maximum(bboxes[:, 0], clip_box[0])\n",
        "    bboxes[:, 1] = np.maximum(bboxes[:, 1], clip_box[1])\n",
        "    bboxes[:, 2] = np.minimum(bboxes[:, 2], clip_box[2])\n",
        "    bboxes[:, 3] = np.minimum(bboxes[:, 3], clip_box[3])\n",
        "    new_areas = area(bboxes)\n",
        "    delta_area = (areas - new_areas) / areas\n",
        "    mask = np.where(delta_area < 1 - alpha)\n",
        "    bboxes = bboxes[mask[0]]\n",
        "    return bboxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkd15njwSBtZ",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def generate_anchors(base_size=16, ratios=[0.5, 1, 2], scales=2**np.arange(3, 6)):\n",
        "    \"\"\"\n",
        "    Generate anchor (reference) windows by enumerating aspect ratios X\n",
        "    scales wrt a reference (0, 0, 15, 15) window.\n",
        "    \"\"\"\n",
        "    base_anchor = np.array([1, 1, base_size, base_size], dtype='float32') - 1\n",
        "    ratio_anchors = _ratio_enum(base_anchor, ratios)\n",
        "    anchors = np.vstack([_scale_enum(ratio_anchors[i, :], scales) for i in range(ratio_anchors.shape[0])])\n",
        "    return anchors\n",
        "\n",
        "def _whctrs(anchor):\n",
        "    \"\"\"\n",
        "    Return width, height, x center, and y center for an anchor (window).\n",
        "    \"\"\"\n",
        "    w = anchor[2] - anchor[0] + 1\n",
        "    h = anchor[3] - anchor[1] + 1\n",
        "    x_ctr = anchor[0] + 0.5 * (w - 1)\n",
        "    y_ctr = anchor[1] + 0.5 * (h - 1)\n",
        "    return w, h, x_ctr, y_ctr\n",
        "\n",
        "def _mkanchors(ws, hs, x_ctr, y_ctr):\n",
        "    \"\"\"\n",
        "    Given a vector of widths (ws) and heights (hs) around a center\n",
        "    (x_ctr, y_ctr), output a set of anchors (windows).\n",
        "    \"\"\"\n",
        "    ws = ws[:, np.newaxis]\n",
        "    hs = hs[:, np.newaxis]\n",
        "    anchors = np.hstack((x_ctr - 0.5 * (ws - 1), y_ctr - 0.5 * (hs - 1), x_ctr + 0.5 * (ws - 1), y_ctr + 0.5 * (hs - 1)))\n",
        "    return anchors\n",
        "\n",
        "def _ratio_enum(anchor, ratios):\n",
        "    \"\"\"\n",
        "    Enumerate a set of anchors for each aspect ratio wrt an anchor.\n",
        "    \"\"\"\n",
        "    w, h, x_ctr, y_ctr = _whctrs(anchor)\n",
        "    size = w * h\n",
        "    size_ratios = size / ratios\n",
        "    ws = np.round(np.sqrt(size_ratios))\n",
        "    hs = np.round(ws * ratios)\n",
        "    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
        "    return anchors\n",
        "\n",
        "def _scale_enum(anchor, scales):\n",
        "    \"\"\"\n",
        "    Enumerate a set of anchors for each scale wrt an anchor.\n",
        "    \"\"\"\n",
        "    w, h, x_ctr, y_ctr = _whctrs(anchor)\n",
        "    ws = w * scales\n",
        "    hs = h * scales\n",
        "    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
        "    return anchors\n",
        "\n",
        "def get_all_anchors(stride=None, sizes=None):\n",
        "    \"\"\"\n",
        "    Get all anchors in the largest possible image, shifted, floatbox\n",
        "    Args:\n",
        "        stride (int): the stride of anchors.\n",
        "        sizes (tuple[int]): the sizes (sqrt area) of anchors\n",
        "\n",
        "    Returns:\n",
        "        anchors: SxSxNUM_ANCHORx4, where S == ceil(MAX_SIZE/STRIDE), floatbox\n",
        "        The layout in the NUM_ANCHOR dim is NUM_RATIO x NUM_SIZE.\n",
        "\n",
        "    \"\"\"\n",
        "    if stride is None:\n",
        "        stride = ANCHOR_STRIDE\n",
        "    if sizes is None:\n",
        "        sizes = ANCHOR_SIZES\n",
        "    # Generates a NAx4 matrix of anchor boxes in (x1, y1, x2, y2) format. Anchors\n",
        "    # are centered on stride / 2, have (approximate) sqrt areas of the specified\n",
        "    # sizes, and aspect ratios as given.\n",
        "    cell_anchors = generate_anchors(stride, scales=np.array(sizes, dtype=np.float) / stride, ratios=np.array(ANCHOR_RATIOS, dtype=np.float))\n",
        "    # anchors are intbox here.\n",
        "    # anchors at featuremap [0,0] are centered at fpcoor (8,8) (half of stride)\n",
        "    field_size = int(np.ceil(MAX_SIZE / stride))\n",
        "    shifts = np.arange(0, field_size) * stride\n",
        "    shift_x, shift_y = np.meshgrid(shifts, shifts)\n",
        "    shift_x = shift_x.flatten()\n",
        "    shift_y = shift_y.flatten()\n",
        "    shifts = np.vstack((shift_x, shift_y, shift_x, shift_y)).transpose()\n",
        "    K = shifts.shape[0]\n",
        "\n",
        "    A = cell_anchors.shape[0]\n",
        "    field_of_anchors = (\n",
        "        cell_anchors.reshape((1, A, 4)) +\n",
        "        shifts.reshape((1, K, 4)).transpose((1, 0, 2)))\n",
        "    field_of_anchors = field_of_anchors.reshape((field_size, field_size, A, 4))\n",
        "    field_of_anchors = field_of_anchors.astype('float32')\n",
        "    field_of_anchors[:, :, :, [2, 3]] += 1\n",
        "    return field_of_anchors\n",
        "\n",
        "def decode_bbox_target(box_predictions, anchors):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        box_predictions: (..., 4), logits\n",
        "        anchors: (..., 4), floatbox. Must have the same shape\n",
        "\n",
        "    Returns:\n",
        "        box_decoded: (..., 4), float32. With the same shape.\n",
        "    \"\"\"\n",
        "    orig_shape = tf.shape(anchors)\n",
        "    box_pred_txtytwth = tf.reshape(box_predictions, (-1, 2, 2))\n",
        "    box_pred_txty, box_pred_twth = tf.split(box_pred_txtytwth, 2, axis=1)\n",
        "    anchors_x1y1x2y2 = tf.reshape(anchors, (-1, 2, 2))\n",
        "    anchors_x1y1, anchors_x2y2 = tf.split(anchors_x1y1x2y2, 2, axis=1)\n",
        "\n",
        "    waha = anchors_x2y2 - anchors_x1y1\n",
        "    xaya = (anchors_x2y2 + anchors_x1y1) * 0.5\n",
        "    clip = np.log(MAX_SIZE / 16.)\n",
        "    wbhb = tf.exp(tf.minimum(box_pred_twth, clip)) * waha\n",
        "    xbyb = box_pred_txty * waha + xaya\n",
        "    x1y1 = xbyb - wbhb * 0.5\n",
        "    x2y2 = xbyb + wbhb * 0.5\n",
        "    out = tf.concat([x1y1, x2y2], axis=-2)\n",
        "    return tf.reshape(out, orig_shape)\n",
        "\n",
        "def narrow_to_c4(featuremaps, anchor_boxes):\n",
        "    \"\"\"\n",
        "    Slice anchors to the spatial size of this featuremap.\n",
        "    \"\"\"\n",
        "    shape2d = tf.shape(featuremaps)[2:]  # h,w\n",
        "    slice4d = tf.concat([shape2d, [-1, -1]], axis=0)\n",
        "    anchor_boxes = tf.slice(anchor_boxes, [0, 0, 0, 0], slice4d)\n",
        "    return anchor_boxes\n",
        "\n",
        "def clip_boxes(boxes, window, name=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        boxes: nx4, xyxy\n",
        "        window: [h, w]\n",
        "    \"\"\"\n",
        "    boxes = tf.maximum(boxes, 0.0)\n",
        "    m = tf.tile(tf.reverse(window, [0]), [2])  # (4,)\n",
        "    boxes = tf.minimum(boxes, tf.to_float(m), name=name)\n",
        "    return boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_VD5zvviSBtc",
        "colab": {}
      },
      "source": [
        "def generate_rpn_proposals(boxes_and_scores, img_shape, pre_nms_topk, post_nms_topk):\n",
        "    \"\"\"\n",
        "    Sample RPN proposals by the following steps:\n",
        "    1. Pick top k1 by scores\n",
        "    2. NMS them\n",
        "    3. Pick top k2 by scores. Default k2 == k1, i.e. does not filter the NMS output.\n",
        "\n",
        "    Args:\n",
        "        boxes: nx4 float dtype, the proposal boxes. Decoded to floatbox already\n",
        "        scores: n float, the logits\n",
        "        img_shape: [h, w]\n",
        "        pre_nms_topk, post_nms_topk (int): See above.\n",
        "\n",
        "    Returns:\n",
        "        boxes: kx4 float\n",
        "        scores: k logits\n",
        "    \"\"\"\n",
        "    boxes = boxes_and_scores[0]\n",
        "    scores = boxes_and_scores[1]\n",
        "\n",
        "    assert boxes.shape.ndims == 2, boxes.shape\n",
        "    if post_nms_topk is None:\n",
        "        post_nms_topk = pre_nms_topk\n",
        "\n",
        "    topk = tf.minimum(pre_nms_topk, tf.size(scores))\n",
        "    topk_scores, topk_indices = tf.nn.top_k(scores, k=topk, sorted=False)\n",
        "    topk_boxes = tf.gather(boxes, topk_indices)\n",
        "    topk_boxes = clip_boxes(topk_boxes, img_shape)\n",
        "\n",
        "    topk_boxes_x1y1x2y2 = tf.reshape(topk_boxes, (-1, 2, 2))\n",
        "    topk_boxes_x1y1, topk_boxes_x2y2 = tf.split(topk_boxes_x1y1x2y2, 2, axis=1)\n",
        "    wbhb = tf.squeeze(topk_boxes_x2y2 - topk_boxes_x1y1, axis=1)\n",
        "    valid = tf.reduce_all(wbhb > MIN_SIZE, axis=1)\n",
        "    topk_valid_boxes_x1y1x2y2 = tf.boolean_mask(topk_boxes_x1y1x2y2, valid)\n",
        "    topk_valid_scores = tf.boolean_mask(topk_scores, valid)\n",
        "\n",
        "    topk_valid_boxes_y1x1y2x2 = tf.reshape(tf.reverse(topk_valid_boxes_x1y1x2y2, axis=[2]), (-1, 4), name='nms_input_boxes')\n",
        "    nms_indices = tf.image.non_max_suppression(topk_valid_boxes_y1x1y2x2, topk_valid_scores, max_output_size=post_nms_topk, iou_threshold=PROPOSAL_NMS_THRESH)\n",
        "\n",
        "    topk_valid_boxes = tf.reshape(topk_valid_boxes_x1y1x2y2, (-1, 4))\n",
        "    proposal_boxes = tf.gather(topk_valid_boxes, nms_indices)\n",
        "    proposal_scores = tf.gather(topk_valid_scores, nms_indices)\n",
        "    return [tf.stop_gradient(proposal_boxes, name='boxes'), tf.stop_gradient(proposal_scores, name='scores')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LA7VFoofSBtf",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.layers import Conv2D, Input, Activation, Lambda\n",
        "from keras.layers import BatchNormalization, MaxPooling2D, ZeroPadding2D, Add\n",
        "from keras.models import Model\n",
        "\n",
        "def resnet_layer(inputs, name, kernel_size=(1,1), num_filters=64, stride=1, padding='same', activation=True, batch_normalization=True):\n",
        "    conv = Conv2D(kernel_size=kernel_size, filters=num_filters, strides=stride, padding=padding, use_bias=False, name='C' + name, data_format='channels_first')\n",
        "    x = conv(inputs)\n",
        "    if batch_normalization == True:\n",
        "        x = BatchNormalization(name='bn' + name, axis=1)(x)\n",
        "    if activation == True:\n",
        "        x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(inputs, name, kernel_size=(1,1), stride=1, num_filters=64, shortcut_connection=False, first_stage=False):\n",
        "    num_filters_out = num_filters * 4\n",
        "    z = inputs\n",
        "    if shortcut_connection == True:\n",
        "        if first_stage == True:\n",
        "            stride = 1\n",
        "        else:\n",
        "            stride = 2\n",
        "            z = Lambda(lambda x: x[:, :, :-1, :-1], name=name + 'shortcut_slice')(inputs)\n",
        "        y = resnet_layer(z, kernel_size=kernel_size, num_filters=num_filters_out, stride=stride, activation=False, batch_normalization=True, name=name + '3')\n",
        "    else:\n",
        "        y = z\n",
        "\n",
        "    x = resnet_layer(inputs, kernel_size=kernel_size, num_filters=num_filters, stride=1, name=name + '0')\n",
        "    if stride == 2:\n",
        "        x = ZeroPadding2D(padding=((1, 0), (1, 0)), data_format='channels_first')(x)\n",
        "        x = resnet_layer(x, kernel_size=(3,3), num_filters=num_filters, stride=stride, padding='valid', name=name + '1')\n",
        "    else:\n",
        "        x = resnet_layer(x, kernel_size=(3,3), num_filters=num_filters, stride=stride, name=name + '1')\n",
        "    x = resnet_layer(x, kernel_size=kernel_size, num_filters=num_filters_out, stride=1, activation=False, name=name + '2')\n",
        "    sumed = Add()([x, y])\n",
        "    out = Activation('relu')(sumed)\n",
        "    return out\n",
        "\n",
        "def resnet50_c4(inputs):\n",
        "    blocks_per_stage = {0: 3, 1: 4, 2: 6}\n",
        "    num_filters = 64\n",
        "    x = ZeroPadding2D(padding=((3, 2), (3, 2)), data_format='channels_first')(inputs)\n",
        "    x = resnet_layer(inputs=x, kernel_size=(7,7), stride=2, padding='valid', name='1_bl0_0')\n",
        "    x = ZeroPadding2D(padding=((1, 0), (1, 0)), data_format='channels_first')(x)\n",
        "    x = MaxPooling2D((3,3), strides=2, padding='valid', name='maxpool', data_format='channels_first')(x)\n",
        "\n",
        "    c234 = []\n",
        "    for stage in range(3):\n",
        "        first_stage = False if stage != 0 else True\n",
        "        num_blocks = blocks_per_stage[stage]\n",
        "        for block in range(num_blocks):\n",
        "            shortcut_connection = False if block != 0 else True\n",
        "            basename = str(stage+2) + '_bl' + str(block) + '_'\n",
        "            x = residual_block(x, num_filters=num_filters, shortcut_connection=shortcut_connection, first_stage=first_stage, name=basename)\n",
        "        c234.append(x)\n",
        "        num_filters *= 2\n",
        "    return c234\n",
        "\n",
        "def rpn_head(c4):\n",
        "    conv_0 = Conv2D(kernel_size=(3,3), filters=1024, strides=1, padding='same', name='rpn_conv0', activation='relu', data_format='channels_first')(c4)\n",
        "    label_logits = Conv2D(kernel_size=(1,1), filters=15, strides=1, padding='same', name='trainable/rpn_class', data_format='channels_first')(conv_0)\n",
        "    box_logits = Conv2D(kernel_size=(1,1), filters=60, strides=1, padding='same', name='trainable/rpn_box', data_format='channels_first')(conv_0)\n",
        "    label_logits = Lambda(lambda x: tf.transpose(x, [0, 2, 3, 1]))(label_logits)\n",
        "    label_logits = Lambda(lambda x: tf.squeeze(x, 0))(label_logits)\n",
        "    shape = tf.shape(box_logits)\n",
        "    box_logits = Lambda(lambda x: tf.transpose(x, [0, 2, 3, 1]))(box_logits)\n",
        "    box_logits = Lambda(lambda x: tf.reshape(x, tf.stack([shape[2], shape[3], 15, 4])))(box_logits)\n",
        "    return [label_logits, box_logits]\n",
        "\n",
        "def build_model(input):\n",
        "    inputs = Input(tensor=input)\n",
        "    c2, c3, c4 = resnet50_c4(inputs)\n",
        "\n",
        "    # Object Detection\n",
        "    rpn_label_logits, rpn_box_logits = rpn_head(c4)\n",
        "    anchors = Lambda(narrow_to_c4, arguments={'anchor_boxes': get_all_anchors()})(c4)\n",
        "    image_shape2d = tf.shape(input)[2:]\n",
        "    pred_boxes_decoded = Lambda(decode_bbox_target, arguments={'anchors': anchors})(rpn_box_logits)\n",
        "    pred_boxes_decoded = Lambda(lambda x: tf.reshape(x, [-1, 4]))(pred_boxes_decoded)\n",
        "    rpn_label_logits = Lambda(lambda x: tf.reshape(x, [-1]))(rpn_label_logits)\n",
        "    proposal_boxes, proposal_scores = Lambda(generate_rpn_proposals, arguments={'img_shape': image_shape2d, 'pre_nms_topk': TEST_PRE_NMS_TOPK, 'post_nms_topk': TEST_POST_NMS_TOPK}, name='proposals')([pred_boxes_decoded, rpn_label_logits])\n",
        "    model = Model(inputs=inputs, outputs=[proposal_boxes, proposal_scores])\n",
        "    return model\n",
        "\n",
        "input = tf.placeholder(tf.float32, shape=(1,3,None,None))\n",
        "model = build_model(input)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BmT9tl96SBti",
        "colab": {}
      },
      "source": [
        "def normalize_image(img, mean, std):\n",
        "    mean = mean[::-1]\n",
        "    std = std[::-1]\n",
        "    new_img = (img - mean) / std\n",
        "    new_img = np.transpose(new_img, (2, 0, 1))\n",
        "    new_img = new_img[np.newaxis, :]\n",
        "    return new_img\n",
        "\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "\n",
        "# Defining the graph\n",
        "input = tf.placeholder(tf.float32, shape=(1, 3, None, None))\n",
        "model = build_model(input)\n",
        "proposal_boxes, proposal_scores = model(input)\n",
        "\n",
        "PIXEL_MEAN = [123.675, 116.28, 103.53]\n",
        "PIXEL_STD = [58.395, 57.12, 57.375]\n",
        "\n",
        "with sess.as_default():\n",
        "    model.load_weights('drive/My Drive/weights.h5', by_name=True)\n",
        "    print('*** Training images ***')\n",
        "    train_pred = {}\n",
        "    for filename in train_images:\n",
        "        print(filename)\n",
        "        normalized_img = normalize_image(train_images.get(filename)[0], mean=PIXEL_MEAN, std=PIXEL_STD)\n",
        "        bboxes, scores = sess.run([proposal_boxes, proposal_scores], feed_dict={input: normalized_img})\n",
        "        train_pred.setdefault(filename,[]).append(bboxes)\n",
        "    print('*** Testing images ***')\n",
        "    test_pred = {}\n",
        "    for filename in test_images:\n",
        "        print(filename)\n",
        "        normalized_img = normalize_image(test_images.get(filename)[0], mean=PIXEL_MEAN, std=PIXEL_STD)\n",
        "        bboxes, scores = sess.run([proposal_boxes, proposal_scores], feed_dict={input: normalized_img})\n",
        "        test_pred.setdefault(filename,[]).append(bboxes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZVIpkvYpAEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# save boxes in order to save time\n",
        "with open('drive/My Drive/models/train_pred.pickle', 'wb') as fp:\n",
        "    pickle.dump(train_pred, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('drive/My Drive/models/test_pred.pickle', 'wb') as fp:\n",
        "    pickle.dump(test_pred, fp, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb7TobZ7jhtq",
        "colab_type": "text"
      },
      "source": [
        "## Generate the final dataset\n",
        "\n",
        "The final dataset contains the ground truth images alongside anchor boxes with IOU>=0.5, labeled according to the sign class they belong to, and roughly 12.000 randomly selected noise images, labeled as -1. Noise images are considered boxes with IOU<=0.2. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooi6oay3pAEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pickle\n",
        "# import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K9TtOhaLpAEZ",
        "colab": {}
      },
      "source": [
        "# # reload boxes from pickle\n",
        "# with open('drive/My Drive/models/train_pred.pickle', 'rb') as fp:\n",
        "#     train_pred = pickle.load(fp)\n",
        "# with open('drive/My Drive/models/test_pred.pickle', 'rb') as fp:\n",
        "#     test_pred = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2mbzlRN8pAEb",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "def get_bin_labels(number_of_images, n_bbox):\n",
        "    with open('drive/My Drive/data/bin_labels.txt', 'w+') as file:\n",
        "        \n",
        "        # add negatives\n",
        "        counter = 0\n",
        "        counter2 = 0\n",
        "        ms = 0\n",
        "        ratioList = []\n",
        "        dimx = []\n",
        "        dimy = []\n",
        "        for i, v in {**train_pred, **test_pred}.items():\n",
        "\n",
        "            # print(i)\n",
        "            # print(v)\n",
        "            noise_images = 0\n",
        "            skip = 0\n",
        "            gr_bboxes = []\n",
        "            gr_labels = []\n",
        "            unique_signs = []\n",
        "            if i in train_files:\n",
        "              # aux = train_images.get(i)[0].copy()\n",
        "              for idx in [l for l, x in enumerate(train_files) if x == i]:\n",
        "                gbbox = train_bboxes[idx]\n",
        "                gr_bboxes.append(gbbox)\n",
        "                gr_labels.append(train_labels[idx])\n",
        "                gr = abs((int(gbbox[0])-int(gbbox[2]))/(int(gbbox[1])-int(gbbox[3])))\n",
        "                if gr<1:\n",
        "                  ratioList.append(1/gr)\n",
        "                else:\n",
        "                  ratioList.append(gr)\n",
        "                dimx.append(abs(int(gbbox[0])-int(gbbox[2])))\n",
        "                dimy.append(abs(int(gbbox[1])-int(gbbox[3])))\n",
        "                file.write(\n",
        "                    i.split('/')[-1]+';'+\n",
        "                    str(int(gbbox[0]))+';'+\n",
        "                    str(int(gbbox[1]))+';'+\n",
        "                    str(int(gbbox[2]))+';'+\n",
        "                    str(int(gbbox[3]))+';'+\n",
        "                    str(train_labels[idx]))\n",
        "                file.write('\\n')\n",
        "                # print(gbbox)\n",
        "\n",
        "            if i in test_files:\n",
        "              # aux = test_images.get(i)[0].copy()\n",
        "              for idx in [l for l, x in enumerate(test_files) if x == i]:\n",
        "                gbbox = test_bboxes[idx]\n",
        "                gr_bboxes.append(gbbox)\n",
        "                gr_labels.append(test_labels[idx])\n",
        "                gr = abs((int(gbbox[0])-int(gbbox[2]))/(int(gbbox[1])-int(gbbox[3])))\n",
        "                if gr<1:\n",
        "                  ratioList.append(1/gr)\n",
        "                else:\n",
        "                  ratioList.append(gr)\n",
        "                dimx.append(abs(int(gbbox[0])-int(gbbox[2])))\n",
        "                dimy.append(abs(int(gbbox[1])-int(gbbox[3])))\n",
        "                file.write(\n",
        "                    i.split('/')[-1]+';'+\n",
        "                    str(int(gbbox[0]))+';'+\n",
        "                    str(int(gbbox[1]))+';'+\n",
        "                    str(int(gbbox[2]))+';'+\n",
        "                    str(int(gbbox[3]))+';'+\n",
        "                    str(test_labels[idx]))\n",
        "                file.write('\\n')         \n",
        "            \n",
        "            # save each detected bbox to file and add label\n",
        "            for bbox in v[0]:\n",
        "                \n",
        "                #filter out some boxes before tagging them as negatives\n",
        "                dx = int(bbox[0])-int(bbox[2])\n",
        "                dy = int(bbox[1])-int(bbox[3])\n",
        "#                 tdx.append(abs(dx))\n",
        "#                 tdy.append(abs(dy))\n",
        "                ratio = abs(dy/dx)\n",
        "                if ratio<1:\n",
        "                    ratio=1/ratio\n",
        "                if ratio>2 or abs(dx)>96 or abs(dy)>96:\n",
        "                    continue                \n",
        "                \n",
        "                temp = []\n",
        "                for k in range(len(gr_bboxes)):\n",
        "                  # print(i)\n",
        "                  # print(gr_bboxes[k])\n",
        "                  iou_var = iou(np.array([gr_bboxes[k]]).astype('float32'), np.array([bbox]))\n",
        "                  # if float(iou_var[0]>0.5):\n",
        "                  #   print(i)\n",
        "                  #   print(\"ground truth: \", np.array([gr_bboxes[k]]).astype('float32'), \" \", \"bounding box: \", np.array([bbox]))\n",
        "                  #   print(float(iou_var[0]))\n",
        "                  temp.append(float(iou_var[0]))                        \n",
        "                              \n",
        "                \n",
        "                if max(temp, default=0)>=0.5:\n",
        "                  #continue\n",
        "                  # print(i)\n",
        "                  # cv2.rectangle(aux, (int(bbox[0]),int(bbox[1])), (int(bbox[2]),int(bbox[3])), (0,255,0), 3)\n",
        "                  sindex = temp.index(max(temp))\n",
        "                  slabel = gr_labels[sindex]\n",
        "                  if gr_bboxes[sindex][0] not in unique_signs:\n",
        "                    unique_signs.append(gr_bboxes[sindex][0])\n",
        "                  # print(i)\n",
        "                  # print(ratio, dx, dy)\n",
        "                  # print(slabel)\n",
        "                  counter2+=1\n",
        "                  file.write(\n",
        "                      i.split('/')[-1]+';'+\n",
        "                      str(int(bbox[0]))+';'+\n",
        "                      str(int(bbox[1]))+';'+\n",
        "                      str(int(bbox[2]))+';'+\n",
        "                      str(int(bbox[3]))+';'+\n",
        "                      str(int(slabel)))\n",
        "                  file.write('\\n')\n",
        "                elif max(temp, default=0)>0 and max(temp, default=0)<0.2:\n",
        "                  file.write(\n",
        "                      i.split('/')[-1]+';'+\n",
        "                      str(int(bbox[0]))+';'+\n",
        "                      str(int(bbox[1]))+';'+\n",
        "                      str(int(bbox[2]))+';'+\n",
        "                      str(int(bbox[3]))+';-1')\n",
        "                  file.write('\\n')\n",
        "                elif noise_images<n_bbox and skip==0:\n",
        "                  file.write(\n",
        "                      i.split('/')[-1]+';'+\n",
        "                      str(int(bbox[0]))+';'+\n",
        "                      str(int(bbox[1]))+';'+\n",
        "                      str(int(bbox[2]))+';'+\n",
        "                      str(int(bbox[3]))+';-1')\n",
        "                  file.write('\\n')\n",
        "                  noise_images+=1\n",
        "                  skip=10\n",
        "\n",
        "                skip-=1\n",
        "              \n",
        "            \n",
        "            # plt.imshow(cv2.cvtColor(aux, cv2.COLOR_BGR2RGB))\n",
        "            # plt.show()\n",
        "            # print(i)\n",
        "            # print(len(unique_signs))\n",
        "            if len(unique_signs)!=len(gr_bboxes):\n",
        "              ms += len(gr_bboxes)-len(unique_signs)\n",
        "              # print(i)\n",
        "              # print(\"len unique signs: \", len(unique_signs))\n",
        "              # print(\"len ground boxes: \", len(gr_bboxes))\n",
        "            counter+=1\n",
        "            if counter >= number_of_images: break\n",
        "                \n",
        "\n",
        "        print(\"overlaps with ground truth: \", counter2)\n",
        "        print(\"non detected signs: \", ms)\n",
        "        ratioList.sort(reverse = True)\n",
        "        print(\"list of ratios :\", ratioList)\n",
        "        dimx.sort(reverse = True)\n",
        "        print(\"list of dx :\", dimx)\n",
        "        dimy.sort(reverse = True)\n",
        "        print(\"list of dy :\", dimy)\n",
        "\n",
        "number_of_images = 900 # use small number for testing\n",
        "n_bbox = TEST_POST_NMS_TOPK # number of negative bboxes per image\n",
        "get_bin_labels(number_of_images, n_bbox)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09KhKuX2HlW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# run some tests\n",
        "i=0\n",
        "\n",
        "number_of_images = 40\n",
        "\n",
        "# pics = [\"FullIJCNN2013/00014.ppm\", \"FullIJCNN2013/00038.ppm\", \"FullIJCNN2013/00068.ppm\", \"FullIJCNN2013/00072.ppm\", \"FullIJCNN2013/00076.ppm\"]\n",
        "\n",
        "for filename in train_images:\n",
        "    print(filename)\n",
        "    aux = train_images.get(filename)[0].copy()\n",
        "\n",
        "    ground_boxes = []\n",
        "    if filename in train_files:\n",
        "        for idx in [i for i, x in enumerate(train_files) if x == filename]:\n",
        "            bbox = train_bboxes[idx]\n",
        "            ground_boxes.append(bbox)\n",
        "            gr_dx = abs(int(bbox[0])-int(bbox[2]))\n",
        "            gr_dy = abs(int(bbox[1])-int(bbox[3]))\n",
        "            print(\"dx: \", gr_dx, \"dy: \", gr_dy)\n",
        "            cv2.rectangle(aux, (int(bbox[0]),int(bbox[1])), (int(bbox[2]),int(bbox[3])), (0,0,255), 3)\n",
        "\n",
        "    for bbox in train_pred.get(filename)[0]:  \n",
        "        dx = int(bbox[0])-int(bbox[2])\n",
        "        dy = int(bbox[1])-int(bbox[3])\n",
        "        ratio = abs(dy/dx)\n",
        "        if ratio<1:\n",
        "            ratio=1/ratio\n",
        "        if ratio>2 or abs(dx)>96 or abs(dy)>96:\n",
        "            continue\n",
        "\n",
        "        for k in range(len(ground_boxes)):\n",
        "          iou_var = iou(np.array([ground_boxes[k]]).astype('float32'), np.array([bbox]))\n",
        "          if float(iou_var[0])>=0.5:\n",
        "            cv2.rectangle(aux, (int(bbox[0]),int(bbox[1])), (int(bbox[2]),int(bbox[3])), (0,255,0), 3)\n",
        "            \n",
        "    \n",
        "    plt.imshow(cv2.cvtColor(aux, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "    i+=1\n",
        "    if i==number_of_images: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ29V9nOpAEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! sort 'drive/My Drive/data/bin_labels.txt' --output='drive/My Drive/data/bin_labels_sorted.txt'\n",
        "! wc -l 'drive/My Drive/data/bin_labels_sorted.txt'\n",
        "! head -n 10 'drive/My Drive/data/bin_labels_sorted.txt'\n",
        "! tail -n 10 'drive/My Drive/data/bin_labels_sorted.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs1U5--5pAEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is just to  get numbers for traffic signs range in train and test set\n",
        "! wc -l 'drive/My Drive/data/bin_labels_sorted.txt'\n",
        "! grep \"00600.ppm\" -B 5 -A 5 -m 1 'drive/My Drive/data/bin_labels_sorted.txt' --line-number"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}