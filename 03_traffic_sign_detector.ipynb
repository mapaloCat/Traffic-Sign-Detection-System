{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03_traffic_sign_detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapaloCat/Traffic-Sign-Detection-System/blob/master/03_traffic_sign_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "718GBnHeSBsx"
      },
      "source": [
        "## The German Traffic Sign Benchmark\n",
        "\n",
        "Collaborator 1: Panagiotis Michalopoulos\n",
        "\n",
        "Collaborator 2: Filip Finfando"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yXMJLE-tSBsy"
      },
      "source": [
        "Download full data set from http://benchmark.ini.rub.de/?section=gtsdb&subsection=dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnGyc-Pz3qwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spfoNkaG3rh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -c https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
        "!unzip FullIJCNN2013.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AjVJoOb8SBtB",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "IMG_HEIGHT = 600\n",
        "SIGN_SIZE = (96, 96)\n",
        "\n",
        "# Function for reading the images\n",
        "def readImages(rootpath, images_range, signs_range, datapath, scaled):\n",
        "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
        "    Arguments: path to the traffic sign data, for example 'FullIJCNN2013'\n",
        "    Returns:   list of images, list of corresponding labels'''\n",
        "    images = {} # original image\n",
        "    scales = {} # original scale\n",
        "    for num in images_range:\n",
        "        filename = rootpath + '/' + \"{:05d}\".format(num) + '.ppm'\n",
        "        img = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
        "        scale = IMG_HEIGHT / float(img.shape[0])\n",
        "        img_resized = cv2.resize(img, (int(img.shape[1]*scale),int(img.shape[0]*scale)))\n",
        "        images.setdefault(filename,[]).append(img_resized)\n",
        "        scales.setdefault(filename,[]).append(scale)\n",
        "\n",
        "    files = [] # filenames\n",
        "    signs = [] # traffic sign image\n",
        "    bboxes = [] # corresponding box detection\n",
        "    labels = [] # traffic sign type\n",
        "    data = np.genfromtxt(datapath, delimiter=';', dtype=str, usecols=range(0, 6))\n",
        "    for elem in signs_range:\n",
        "        filename = rootpath + '/' + data[elem][0]\n",
        "        img = images.get(filename)[0]\n",
        "        if scaled:\n",
        "          scale = 1\n",
        "        else:\n",
        "          scale = scales.get(filename)[0]\n",
        "        bbox = np.array([int(data[elem][1]), int(data[elem][2]), int(data[elem][3]), int(data[elem][4])]) * scale\n",
        "        sign = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "        sign_resized = cv2.resize(sign, SIGN_SIZE)\n",
        "        files.append(filename)\n",
        "        signs.append(sign_resized)\n",
        "        bboxes.append(bbox)\n",
        "        labels.append(data[elem][5])\n",
        "    return images, files, signs, bboxes, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NWA9VZTuSBtE",
        "colab": {}
      },
      "source": [
        "# The German Traffic Sign Recognition Benchmark\n",
        "train_images, train_files, train_signs, train_bboxes, train_labels = readImages('FullIJCNN2013', range(0,600), range(0,852), 'FullIJCNN2013/gt.txt', False)\n",
        "test_images, test_files, test_signs, test_bboxes, test_labels = readImages('FullIJCNN2013', range(600,900), range(852,1213), 'FullIJCNN2013/gt.txt', False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j0eVsxuvSBtS"
      },
      "source": [
        "## Traffic sign detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BmT9tl96SBti",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('drive/My Drive/models/train_pred.pickle', 'rb') as fp:\n",
        "    train_pred = pickle.load(fp)\n",
        "with open('drive/My Drive/models/test_pred.pickle', 'rb') as fp:\n",
        "    test_pred = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2MbQdzbPSBtl",
        "colab": {}
      },
      "source": [
        "## import binary model\n",
        "\n",
        "from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open('drive/My Drive/models/bin_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "cnn = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "cnn.load_weights(\"drive/My Drive/models/bin_model.h5\")\n",
        "print(\"Loaded binary model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7kRqWua4xDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## import classification model\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('drive/My Drive/models/classification_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "cnn_classifier = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "cnn_classifier.load_weights(\"drive/My Drive/models/classification_model.h5\")\n",
        "print(\"Loaded classification model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "scrolled": true,
        "id": "veNZ0JbX3Ult",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import math\n",
        "\n",
        "# # run some tests\n",
        "# i=0\n",
        "\n",
        "# number_of_images = 20\n",
        "# number_of_boxes_to_draw = 1000\n",
        "\n",
        "\n",
        "# for filename in test_images:\n",
        "#     # Draw predictions\n",
        "#     aux = test_images.get(filename)[0].copy()\n",
        "#     print(filename)\n",
        "#     #print(test_labels[i])\n",
        "    \n",
        "#     counter = 0\n",
        "    \n",
        "#     for bbox in test_pred.get(filename)[0][:number_of_boxes_to_draw]: \n",
        "        \n",
        "#         #filter some boxes before making predictions\n",
        "#         dx = int(bbox[0])-int(bbox[2])\n",
        "#         dy = int(bbox[1])-int(bbox[3])\n",
        "#         ratio = abs(dy/dx)\n",
        "#         if ratio<1:\n",
        "#             ratio=1/ratio\n",
        "#         if ratio>2 or abs(dx)>96 or abs(dy)>96:\n",
        "#             continue\n",
        "        \n",
        "#         # make a prediction\n",
        "#         roi = test_images.get(filename)[0][int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "#         SIGN_SIZE_CNN = (96, 96)\n",
        "#         roi_resized = cv2.resize(roi, SIGN_SIZE_CNN)\n",
        "#         roi_resized = roi_resized.astype('float32')\n",
        "#         roi_resized /= 255.0\n",
        "#         roi_resized = np.reshape(roi_resized, [1,SIGN_SIZE_CNN[0],SIGN_SIZE_CNN[1],3])\n",
        "        \n",
        "#         confidence = cnn.predict(roi_resized)\n",
        "#         counter+=1\n",
        "#         #print(counter, \" confidence: \", confidence, \"\\n\")\n",
        "        \n",
        "#         sign_class = cnn_classifier.predict(roi_resized)\n",
        "        \n",
        "#         # print rectangle if confidence is large\n",
        "#         # those are boxes that we think have the largest probability to have a traffic sign inside\n",
        "#         if confidence[0][1] >= 0.5:\n",
        "#             cv2.rectangle(aux, (int(bbox[0]),int(bbox[1])), (int(bbox[2]),int(bbox[3])), (0,255,0), 3)\n",
        "#             #print(counter, \" sign_class:\", str(np.argmax(sign_class[0])), \" diagonal:\", math.sqrt(dx**2 + dy**2), \"\\n\")\n",
        "            \n",
        "            \n",
        "#         #print(bbox,\"\\n\")\n",
        "#             #sign_class_int = np.where(sign_class[0]==sign_class[0].max())[0][0]\n",
        "# #             print(sign_class_int)\n",
        "\n",
        "\n",
        "\n",
        "#         # print contents of box if you like\n",
        "# #         not_a_sign = aux[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "# #         plt.imshow(cv2.cvtColor(not_a_sign, cv2.COLOR_BGR2RGB))\n",
        "# #         plt.show()\n",
        "            \n",
        "\n",
        "    \n",
        "#     # Draw ground truth\n",
        "#     # this is what we should detect\n",
        "#     if filename in test_files:\n",
        "#         for idx in [i for i, x in enumerate(test_files) if x == filename]:\n",
        "#             bbox = test_bboxes[idx]\n",
        "#             #print(bbox)\n",
        "#             dx = int(bbox[0])-int(bbox[2])\n",
        "#             dy = int(bbox[1])-int(bbox[3])\n",
        "#             ratio = abs(dy/dx)\n",
        "# #             if ratio<1:\n",
        "# #                 print(1/ratio)\n",
        "# #             else:\n",
        "# #                 print(ratio)\n",
        "#             print(bbox)\n",
        "#             cv2.rectangle(aux, (int(bbox[0]),int(bbox[1])), (int(bbox[2]),int(bbox[3])), (0,0,255), 3)\n",
        "            \n",
        "#             # print contents of box if you like\n",
        "# #             sign = aux[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "# #             plt.imshow(cv2.cvtColor(sign, cv2.COLOR_BGR2RGB))\n",
        "# #             plt.show()\n",
        "    \n",
        "#     plt.imshow(cv2.cvtColor(aux, cv2.COLOR_BGR2RGB))\n",
        "#     plt.show()\n",
        "#     i+=1\n",
        "#     if i==number_of_images: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E1fCQnOiSBtp"
      },
      "source": [
        "### Evaluation using Mean Average Precision\n",
        "\n",
        "git clone https://github.com/Cartucho/mAP.git\n",
        "\n",
        "mkdir ground-truth\n",
        "\n",
        "mkdir predicted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20_UitY-8DRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/Cartucho/mAP.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yel4zjl8HlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !mkdir ground-truth\n",
        "\n",
        "# !mkdir predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUUN_yRhDtMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBBftSqQCg4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd mAP/input/ground-truth; \\rm -rf 2007_*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO4du8yX6QqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd mAP/input/detection-results; \\rm -rf *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jpGA-3-mSBtq",
        "colab": {}
      },
      "source": [
        "for filename in test_images:\n",
        "    anns_ofs = open('mAP/input/ground-truth/' + filename[-9:-4:] + '.txt', 'w')\n",
        "    if filename in test_files:\n",
        "        for idx in [i for i, x in enumerate(test_files) if x == filename]:\n",
        "            bbox = test_bboxes[idx]\n",
        "            label = test_labels[idx]\n",
        "            anns_ofs.write(str(label) + ' ' + str(bbox[0]) + ' ' + str(bbox[1]) + ' ' + str(bbox[2]) + ' ' + str(bbox[3]) + '\\n')\n",
        "    anns_ofs.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z6q1jFz_SBtt",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "start = time()\n",
        "for filename in test_images:\n",
        "    prds_ofs = open('mAP/input/detection-results/' + filename[-9:-4:] + '.txt', 'w')\n",
        "    aux = test_images.get(filename)[0].copy()\n",
        "    \n",
        "    for bbox in test_pred.get(filename)[0]:\n",
        "        \n",
        "        #filter some boxes before making predictions\n",
        "        dx = int(bbox[0])-int(bbox[2])\n",
        "        dy = int(bbox[1])-int(bbox[3])\n",
        "        ratio = abs(dy/dx)\n",
        "        if ratio<1:\n",
        "          ratio=1/ratio\n",
        "        if ratio>2 or abs(dx)>96 or abs(dy)>96:\n",
        "          continue\n",
        "        \n",
        "        roi = test_images.get(filename)[0][int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "        SIGN_SIZE_CNN = (96, 96)\n",
        "        roi_resized = cv2.resize(roi, SIGN_SIZE_CNN)\n",
        "        roi_resized = roi_resized.astype('float32')\n",
        "        roi_resized /= 255.0\n",
        "        roi_resized = np.reshape(roi_resized, [1,SIGN_SIZE_CNN[0],SIGN_SIZE_CNN[1],3])\n",
        "    \n",
        "        confidence = cnn.predict(roi_resized)\n",
        "        if confidence[0][1] >= 0.5:\n",
        "          cv2.rectangle(aux, (int(bbox[0]),int(bbox[1])), (int(bbox[2]),int(bbox[3])), (0,0,255), 3)\n",
        "        else:\n",
        "          continue\n",
        "                                                \n",
        "        ## sign class\n",
        "        sign_class = cnn_classifier.predict(roi_resized)\n",
        "#         sign_class_int = np.where(sign_class[0]==sign_class[0].max())[0][0]\n",
        "#         print(sign_class_int)\n",
        "        \n",
        "        \n",
        "        # traffic_sign_class confidence bbox\n",
        "        prds_ofs.write(str(np.argmax(sign_class[0])) + ' ' + str(confidence[0][1]) + ' ' + str(bbox[0]) + ' ' + str(bbox[1]) + ' ' + str(bbox[2]) + ' ' + str(bbox[3]) + '\\n')\n",
        "    prds_ofs.close()\n",
        "    plt.imshow(cv2.cvtColor(aux, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "end = time()\n",
        "print(\"Traffic sign detection took \" + str(end - start) + \" seconds\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "wzSOwPS_3Ul0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ahOUoZ2DSBty",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# Follow previous mAP code in order to evaluate the performance of your neural net\n",
        "%run mAP/main.py -na -np\n",
        "%cd ../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i8Ib05iWSBt2",
        "colab": {}
      },
      "source": [
        "# Sample results obtained using our detector\n",
        "81.53% = 1 AP \n",
        "86.04% = 10 AP \n",
        "71.55% = 11 AP \n",
        "83.11% = 12 AP \n",
        "88.96% = 13 AP \n",
        "96.67% = 14 AP \n",
        "100.00% = 15 AP \n",
        "100.00% = 16 AP \n",
        "69.17% = 17 AP \n",
        "59.09% = 18 AP \n",
        "85.71% = 2 AP \n",
        "62.50% = 22 AP \n",
        "72.62% = 23 AP \n",
        "100.00% = 24 AP \n",
        "65.00% = 25 AP \n",
        "41.90% = 26 AP \n",
        "60.00% = 28 AP \n",
        "0.00% = 29 AP \n",
        "64.44% = 3 AP \n",
        "66.67% = 30 AP \n",
        "0.00% = 31 AP \n",
        "45.00% = 32 AP \n",
        "100.00% = 33 AP \n",
        "66.67% = 34 AP \n",
        "92.50% = 35 AP \n",
        "0.00% = 36 AP \n",
        "100.00% = 37 AP \n",
        "63.75% = 38 AP \n",
        "50.00% = 39 AP \n",
        "83.70% = 4 AP \n",
        "66.67% = 40 AP \n",
        "100.00% = 41 AP \n",
        "90.00% = 42 AP \n",
        "68.98% = 5 AP \n",
        "100.00% = 6 AP \n",
        "95.00% = 7 AP \n",
        "95.00% = 8 AP \n",
        "82.41% = 9 AP \n",
        "mAP = 72.49%\n",
        "\n",
        "Traffic sign detection took 520.6455109119415 seconds"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}